{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction with GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to get complete predictions for whole dataset split into cross-validation folds. For more detailed description of the training refer to the `gcn-link-prediction-demo.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import FullBatchLinkGenerator\n",
    "from stellargraph.layer import GCN, LinkEmbedding\n",
    "from tensorflow import keras\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "from graph import load_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(split, epochs=5000):\n",
    "    (G_train, edge_ids_train, edge_labels_train), (G_test, edge_ids_test, edge_labels_test) = split\n",
    "\n",
    "    train_gen = FullBatchLinkGenerator(G_train, method=\"gcn\")\n",
    "    train_flow = train_gen.flow(edge_ids_train, edge_labels_train)\n",
    "    test_gen = FullBatchLinkGenerator(G_test, method=\"gcn\")\n",
    "    test_flow = test_gen.flow(edge_ids_test, edge_labels_test)\n",
    "\n",
    "    gcn = GCN(\n",
    "        layer_sizes=[256, 256, 256, 256], activations=[\"relu\", \"relu\", \"relu\", \"relu\"], generator=train_gen, dropout=0.25\n",
    "    )\n",
    "\n",
    "    x_inp, x_out = gcn.in_out_tensors()\n",
    "\n",
    "    prediction = LinkEmbedding(activation=\"tanh\", method=\"ip\")(x_out)\n",
    "    prediction = keras.layers.Reshape((-1,))(prediction)\n",
    "\n",
    "    model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=keras.losses.binary_crossentropy,\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(), \n",
    "            keras.metrics.Precision(), \n",
    "            keras.metrics.Recall(),\n",
    "            keras.metrics.AUC()\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_flow, epochs=epochs, validation_data=test_flow, \n",
    "        verbose=0, callbacks=[TqdmCallback(verbose=1)], shuffle=True\n",
    "    )\n",
    "\n",
    "    y_test = test_flow[0][-1][0]\n",
    "    y_prob = model.predict(test_flow)[0]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for edge, p in zip(test_flow[0][0][1][0], y_prob):\n",
    "        phn, gen = edge\n",
    "        rows.append([G_test.nodes()[gen], G_test.nodes()[phn], p])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"Gen\", \"Phn\", \"p\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GCN (local pooling) filters...\n",
      "Using GCN (local pooling) filters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c490f7641d4144938c0775814e3d8567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GCN (local pooling) filters...\n",
      "Using GCN (local pooling) filters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876cd7e3c4504b40822f2f4dfc922489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GCN (local pooling) filters...\n",
      "Using GCN (local pooling) filters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6169ab00b9aa43dc880bfb652cc6d3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GCN (local pooling) filters...\n",
      "Using GCN (local pooling) filters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44beeab4d5974eda95ba75b3aa23f1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GCN (local pooling) filters...\n",
      "Using GCN (local pooling) filters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655b79537d544119942f6fed4eaf83c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F19D1B4D08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gen</th>\n",
       "      <th>Phn</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLC9A1</td>\n",
       "      <td>D1071</td>\n",
       "      <td>0.983144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAGI3</td>\n",
       "      <td>D1071</td>\n",
       "      <td>0.874537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S100A14</td>\n",
       "      <td>D1071</td>\n",
       "      <td>0.728153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1orf35</td>\n",
       "      <td>D1071</td>\n",
       "      <td>0.831546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUPT7L</td>\n",
       "      <td>D1071</td>\n",
       "      <td>0.994575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140596</th>\n",
       "      <td>DDX11</td>\n",
       "      <td>D1222</td>\n",
       "      <td>0.002606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140597</th>\n",
       "      <td>ITPK1</td>\n",
       "      <td>D1222</td>\n",
       "      <td>0.002593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140598</th>\n",
       "      <td>MORF4</td>\n",
       "      <td>D1222</td>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140599</th>\n",
       "      <td>NINJ1</td>\n",
       "      <td>D1222</td>\n",
       "      <td>0.002593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140600</th>\n",
       "      <td>WNT16</td>\n",
       "      <td>D1222</td>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>703008 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gen    Phn         p\n",
       "0        SLC9A1  D1071  0.983144\n",
       "1         MAGI3  D1071  0.874537\n",
       "2       S100A14  D1071  0.728153\n",
       "3       C1orf35  D1071  0.831546\n",
       "4        SUPT7L  D1071  0.994575\n",
       "...         ...    ...       ...\n",
       "140596    DDX11  D1222  0.002606\n",
       "140597    ITPK1  D1222  0.002593\n",
       "140598    MORF4  D1222  0.001918\n",
       "140599    NINJ1  D1222  0.002593\n",
       "140600    WNT16  D1222  0.001918\n",
       "\n",
       "[703008 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "splits = load_splits(sample_test_negatives=False)\n",
    "\n",
    "for split in splits:\n",
    "    dfs.append(train_predict(split))\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
